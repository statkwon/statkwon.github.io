<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Explaining Prediction Models and Individual Predictions with Feature Contributions - ML LAB</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Explaining Prediction Models and Individual Predictions with Feature Contributions" />
<meta property="og:description" content="Abstract 이 논문에서는 어떠한 종류의 Classification 또는 Regression 모형에도 적용할 수 있는 모형 해석 방법에 대해 소개한다. 이 방법은 기존의 방법들과는 달리 가능한 모든 변수 조합을 살핌으로써 변수 간 상호작용을 고려할 수 있다는 장점을 갖는다.
1. Introduction 변수 간 상호작용이 존재하지 않는 Additive Regression Model에서 모든 변수가 표준화된 경우, 회귀 계수를 통해 변수들의 Global Importance를 파악할 수 있다. 반면 단일 예측값에 대한 변수들의 기여도를 알고 싶은 경우에는 다음과 같은 식의 Situational Importance를 사용할 수 있다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://statkwon.github.io/paper_review/explaining_prediction_models_and_individual_predictions_with_feature_contributions/" /><meta property="article:section" content="paper_review" />
<meta property="article:published_time" content="2022-03-28T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-03-28T00:00:00+00:00" />

		<meta itemprop="name" content="Explaining Prediction Models and Individual Predictions with Feature Contributions">
<meta itemprop="description" content="Abstract 이 논문에서는 어떠한 종류의 Classification 또는 Regression 모형에도 적용할 수 있는 모형 해석 방법에 대해 소개한다. 이 방법은 기존의 방법들과는 달리 가능한 모든 변수 조합을 살핌으로써 변수 간 상호작용을 고려할 수 있다는 장점을 갖는다.
1. Introduction 변수 간 상호작용이 존재하지 않는 Additive Regression Model에서 모든 변수가 표준화된 경우, 회귀 계수를 통해 변수들의 Global Importance를 파악할 수 있다. 반면 단일 예측값에 대한 변수들의 기여도를 알고 싶은 경우에는 다음과 같은 식의 Situational Importance를 사용할 수 있다."><meta itemprop="datePublished" content="2022-03-28T00:00:00+00:00" />
<meta itemprop="dateModified" content="2022-03-28T00:00:00+00:00" />
<meta itemprop="wordCount" content="764">
<meta itemprop="keywords" content="XAI,SHAP,Shapley Sampling Value," />
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	<link rel="stylesheet" href="/css/custom.css">

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ML LAB" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ML LAB</div>
					<div class="logo__tagline">To be a skillful ML engineer</div>
				</div>
		</a>
	</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/about/">
				
				<span class="menu__text">About</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Explaining Prediction Models and Individual Predictions with Feature Contributions</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2022-03-28T00:00:00Z">2022-03-28</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/paper-review/" rel="category">Paper Review</a>
	</span>
</div></div>
		</header>
		
<div class="post__toc toc">
	<div class="toc__title">Page content</div>
	<div class="toc__menu">
		<nav id="TableOfContents">
  <ul>
    <li><a href="#abstract">Abstract</a></li>
    <li><a href="#1-introduction">1. Introduction</a></li>
    <li><a href="#2-computing-a-features-contribution">2. Computing a Feature&rsquo;s Contribution</a></li>
    <li><a href="#3-approximation-algorithm">3. Approximation Algorithm</a></li>
    <li><a href="#memo">Memo</a></li>
    <li><a href="#reference">Reference</a></li>
  </ul>
</nav>
	</div>
</div><div class="content post__content clearfix">
			<h2 id="abstract">Abstract</h2>
<hr>
<p>이 논문에서는 어떠한 종류의 Classification 또는 Regression 모형에도 적용할 수 있는 모형 해석 방법에 대해 소개한다. 이 방법은 기존의 방법들과는 달리 가능한 모든 변수 조합을 살핌으로써 변수 간 상호작용을 고려할 수 있다는 장점을 갖는다.</p>
<h2 id="1-introduction">1. Introduction</h2>
<hr>
<p>변수 간 상호작용이 존재하지 않는 Additive Regression Model에서 모든 변수가 표준화된 경우, 회귀 계수를 통해 변수들의 Global Importance를 파악할 수 있다. 반면 단일 예측값에 대한 변수들의 기여도를 알고 싶은 경우에는 다음과 같은 식의 Situational Importance를 사용할 수 있다.</p>
<p>$\begin{aligned}
\phi_i(\mathbf{x})&amp;=f(\mathbf{x})-\text{E}[f\vert X_j=x_j, \forall j\neq i] \\
&amp;=\beta_0+\beta_1x_1+\cdots+\beta_nx_n-\text{E}[\beta_0+\beta_1x_1+\cdots+\beta_iX_i+\cdots+\beta_nx_n] \\
&amp;=\beta_0+\beta_1x_1+\cdots+\beta_nx_n-\beta_0+\beta_1x_1+\cdots+\beta_i\text{E}[X_i]+\cdots+\beta_nx_n \\
&amp;=\beta_ix_i-\beta_i\text{E}[X_i]
\end{aligned}$</p>
<p>즉, $f(\mathbf{x})$라는 예측값에 대한 $i$번째 변수의 Situational Importance는 $f(\mathbf{x})$와 $i$번째 변수의 값이 주어지지 않았을 때 평균적인 예측값의 차이로 정의된다.</p>
<p>이를 축구 경기에 빗대어 표현하자면, 어떤 경기에서 팀이 5점을 득점했을 때 $i$번째 선수의 기여도를</p>
<p>[해당 경기의 득점(5점) $-$ $i$번째 선수를 제외한 나머지 선수들이 모두 해당 경기와 동일하게 득점한 다른 경기들의 평균 득점]으로 계산하는 것으로 생각할 수 있다.</p>
<p>이러한 지표가 유의미하게 받아들여지기 위해서는 득점에 있어 선수들 사이의 협력은 존재하지 않는다는 가정이 필요하다. 하지만 축구 경기에서 대부분의 득점이 다른 팀원들의 도움을 통해 이루어지듯이, 많은 경우 변수 간 상호작용이 존재한다. 따라서 보다 일반적인 모형에 대해 Situational Importance를 적용하는 것은 바람직하지 않다.</p>
<h2 id="2-computing-a-features-contribution">2. Computing a Feature&rsquo;s Contribution</h2>
<hr>
<p>2장에서는 Situational Importance를 수정하여 보다 일반적인 모형(Not Additive)에 적용할 수 있게 만든 방식에 대해 소개하고 있다.</p>
<p>Assumption: $\mathbf{X}\in\mathcal{X}=[0, 1]^n$, $Y\in\mathbb{R}$, $f:\mathcal{X}\rightarrow\mathbb{R}$</p>
<p>우선 어떠한 모형의 예측값 $f(\mathbf{x})$에 대한 특정 변수들($Q\subseteq S=\{1, 2, \ldots, n\}$)의 기여도를 다음과 같이 정의한다.</p>
<p>$\Delta_Q(\mathbf{x})=\text{E}[f\vert X_i=x_i, \forall i\in Q]-\text{E}[f]$</p>
<p>$Q\subseteq S$이므로, 총 $2^n$개의 조합에 대한 기여도를 구할 수 있다.</p>
<p>다음으로 $Q$의 임의의 부분집합 $W$에 대하여 $W$에 속한 변수들 간의 상호작용을 $\mathcal{I}_W(\mathbf{x})$라고 할 때, $\Delta_Q(\mathbf{x})$를 모든 상호작용의 합으로 표현할 수 있다고 가정한다.</p>
<p>이를 식으로 표현하면 $\displaystyle \Delta_Q(\mathbf{x})=\sum_{W\subseteq Q}\mathcal{I}_W(\mathbf{x})$이고, 이 식을 통해 $Q$에 속한 변수들 간의 상호작용을 $\displaystyle \mathcal{I}_Q(\mathbf{x})=\Delta_Q(\mathbf{x})-\sum_{W\subset Q}\mathcal{I}_W(\mathbf{x})$로 계산할 수 있다.</p>
<p>이후 $i$번째 변수가 포함된 모든 상호작용의 가중평균, $\displaystyle \phi_i(\mathbf{x})=\sum_{Q\subseteq S\backslash\{i\}}\dfrac{\mathcal{I}_{W\cup\{i\}}(\mathbf{x})}{\vert W\vert+1}$를 예측값 $f(\mathbf{x})$에 대한 $i$번째 변수의 기여도로 사용한다.</p>
<p>이 논문에서는 이러한 과정을 통해 구한 $\phi_i(\mathbf{x})$가 Value Function이 $\Delta_Q(\mathbf{x})$일 때 $\Delta_S(\mathbf{x})=f(\mathbf{x})-\text{E}[f]$에 대한 $i$번째 변수의 Shapley Value와 같음을 밝히고 있다.</p>
<p>$\begin{aligned}
\phi_i(\mathbf{x})&amp;=\sum_{Q\subseteq S\backslash\{i\}}\dfrac{\vert Q\vert!(\vert S\vert-\vert Q\vert-1)!}{\vert S\vert!}(\Delta_{Q\cup\{i\}}(\mathbf{x})-\Delta_Q(\mathbf{x})) \\
&amp;=\sum_{Q\subseteq S\backslash\{i\}}\dfrac{\vert Q\vert!(\vert S\vert-\vert Q\vert-1)!}{\vert S\vert!}(\text{E}[f\vert X_j=x_j, \forall j\in Q\cup\{i\}]-\text{E}[f\vert X_j=x_j, \forall j\in Q])
\end{aligned}$</p>
<p><strong>Properties of $\phi_i(\mathbf{x})$</strong></p>
<ul>
<li>$\sum_{i=1}^n\phi_i(\mathbf{x})=\Delta_S(\mathbf{x})$ - 모든 변수에 대한 Shapley Value의 합은 $\Delta_S(\mathbf{x})$, 즉, $f(\mathbf{x})-\text{E}[f]$와 같다.</li>
<li>$\forall W\subseteq S\backslash\{i\}:\Delta_W=\Delta_{W\cup\{j\}}\Rightarrow\phi_i(\mathbf{x})=0$ - 어떤 변수가 예측값에 영향을 미치지 않을 경우, 해당 변수의 기여도는 $0$으로 책정된다.</li>
<li>$\forall W\subseteq S\backslash\{i, j\}:\Delta_{W\cup\{i\}}=\Delta_{W\cup\{j\}}\Rightarrow\phi_i(\mathbf{x})=\phi_j(\mathbf{x})$ - 서로 다른 두 변수가 예측값에 미치는 영향이 동일할 경우, 두 변수의 기여도는 동일하게 책정된다.</li>
<li>$\forall \mathbf{x}, \mathbf{y}\in\mathcal{X}:\phi(\mathbf{x}+\mathbf{y})=\phi(\mathbf{x})+\phi(\mathbf{y})$, where $\Delta_Q(\mathbf{x}+\mathbf{y})=\Delta_Q(\mathbf{x})+\Delta_Q(\mathbf{y})$ for all $Q\subseteq S$ - Additivity across Instances</li>
</ul>
<h2 id="3-approximation-algorithm">3. Approximation Algorithm</h2>
<hr>
<p>$\phi_i(\mathbf{x})$의 정확한 값을 계산하는 것의 시간 복잡도는 $O(2^n)$으로, 변수의 개수가 많을 수록 실질적인 계산이 불가능하다. 3장에서는 그 값을 근사하기 위한 알고리즘에 대해 소개하고 있다.</p>
<p><strong>Theoretical Background for Algorithm</strong></p>
<p>Shapley Value의 Alternative Formula를 사용하여 $\phi_i(\mathbf{x})$를 다음과 같은 형태로 표현할 수 있다.</p>
<p>$\begin{aligned}
\phi_i(\mathbf{x})&amp;=\sum_{Q\subseteq S\backslash\{i\}}\dfrac{\vert Q\vert!(\vert S\vert-\vert Q\vert-1)!}{\vert S\vert!}(\Delta_{Q\cup\{i\}}(\mathbf{x})-\Delta_Q(\mathbf{x})) \\
&amp;=\dfrac{1}{n!}\sum_{\mathcal{O}\in\pi(n)}(\Delta_{\text{Pre}^i(\mathcal{O})\cup\{i\}}-\Delta_{\text{Pre}^i(\mathcal{O})})
\end{aligned}$</p>
<p>where $\pi(n)$ is the set of all ordered permutations of the feature indices $\{1, 2, \ldots, n\}$, $\text{Pre}^i(\mathcal{O})$ is the set of all indices that precede $i$ in permutation $\mathcal{O}\in\pi(n)$</p>
<p>(ex. $\pi(3)=\{\{1, 2, 3\}, \{1, 3, 2\}, \{2, 1, 3\}, \{2, 3, 1\}, \{3, 1, 2\}, \{3, 2, 1\}\}$, If $\mathcal{O}=\{2, 1, 3\}$, then $\text{Pre}^1(\mathcal{O})=\{2\}$.)</p>
<p>$\Delta$-terms의 계산 비용이 작을 경우 $\Delta_{\text{Pre}^i(\mathcal{O})\cup\{i\}}-\Delta_{\text{Pre}^i(\mathcal{O})}$에 대한 Monte-Carlo Sampling을 사용하여 $\phi_i(\mathbf{x})$를 추정할 수 있다.
하지만 $\Delta$-terms의 계산 비용은 $O(2^n)$이므로, Sampling Algorithm을 사용하기 위해서는 추가적인 가정이 필요하다.</p>
<p>이 논문에서는 변수들 사이의 독립을 가정한다. 해당 가정 하에서 $\Delta_Q(\mathbf{x})$를 다음과 같은 간단한 형태로 나타낼 수 있다.</p>
<p>$\begin{aligned}
\Delta_Q(\mathbf{x})&amp;=\text{E}[f\vert X_i=x_i, \forall i\in Q]-\text{E}[f] \\
&amp;=\text{E}_{\mathbf{X}_{Q^c}\vert\mathbf{X}_Q}[f]-\text{E}[f] \\
&amp;=\text{E}_{\mathbf{X}_{Q^c}}[f]-\text{E}[f] \qquad (\because\text{Feature Independece}) \\
&amp;=\sum_{\mathbf{w}\in\mathcal{X}}p(\mathbf{w})(f(\mathbf{w}_{[w_i=x_i, i\in Q]})-f(\mathbf{w}))
\end{aligned}$</p>
<p>where $\mathbf{w}_{[w_i=x_i, i\in S]}$ denotes instance $\mathbf{w}$ with the value of feature $i$ replaced with that feature&rsquo;s value in instance $\mathbf{x}$, for each $i\in S$</p>
<p>(ex. $\mathbf{w}=\left&lt;2, 4, 6\right&gt;$, $\mathbf{x}=\left&lt;3, 5, 7\right&gt;$, $\mathbf{w}_{[w_i=x_i, i\in\{1, 3\}]}=\left&lt;3, 4, 7\right&gt;$)</p>
<p>이를 $\phi_i(\mathbf{x})$의 식에 대입하면 $\displaystyle \phi_i(\mathbf{x})=\dfrac{1}{n!}\sum_{\mathcal{O}\in\pi(n)}\sum_{\mathbf{w}\in\mathcal{X}}p(\mathbf{w})\cdot\left(f(\mathbf{w}_{[w_j=x_j, j\in\text{Pre}^i(\mathcal{O})\cup\{i\}]})-f(\mathbf{w}_{[w_j=x_j, j\in\text{Pre}^i(\mathcal{O})]})\right)$와 같은 식을 얻을 수 있다.</p>
<p>이후 $V_{\mathcal{O}, \mathbf{w}\in\mathcal{X}}=\left(f(\mathbf{w}_{[w_j=x_j, j\in\text{Pre}^i(\mathcal{O})\cup\{i\}]})-f(\mathbf{w}_{[w_j=x_j, j\in\text{Pre}^i(\mathcal{O})]})\right)$로부터 $p(\mathbf{w})$의 확률로 추출한 $m$개의 Sample $V_j$를 사용하여 $\phi_i(\mathbf{x})$를 추정할 수 있다.</p>
<p>$\displaystyle \hat{\phi}_i(\mathbf{x})=\dfrac{1}{m}\sum_{j=1}^mV_j$</p>
<p>이때 $\hat{\phi}_i(\mathbf{x})$는 근사적으로 평균이 $\phi_i(\mathbf{x})$이고 분산이 $\frac{\sigma_i^2}{m}$인 정규분포를 따른다. ($\sigma_i^2$ is the population variance.) 즉, $\hat{\phi}_i(\mathbf{x})$는 $\phi_i(\mathbf{x})$에 대한 Consistent Estimator이다.</p>
<p><strong>Algorithm</strong> - Approximating the $i$th feature&rsquo;s contribution for model $f$, instance $\mathbf{x}\in\mathcal{X}$ and distribution $p$</p>
<figure><img src="/paper_review/shapley_sampling_values1.png" width="700"/>
</figure>

<h2 id="memo">Memo</h2>
<hr>
<ul>
<li>Shapley Sampling Values는 Feature Independence를 가정한다.</li>
</ul>
<h2 id="reference">Reference</h2>
<hr>
<ol>
<li>Štrumbelj, E., &amp; Kononenko, I. (2014). Explaining prediction models and individual predictions with feature contributions. Knowledge and information systems, 41(3), 647-665.</li>
<li>Štrumbelj, E., &amp; Kononenko, I. (2011, April). A general method for visualizing and explaining black-box regression models. In International Conference on Adaptive and Natural Computing Algorithms (pp. 21-30). Springer, Berlin, Heidelberg.</li>
<li>Strumbelj, E., &amp; Kononenko, I. (2010). An efficient explanation of individual classifications using game theory. The Journal of Machine Learning Research, 11, 1-18.</li>
<li><a href="https://en.wikipedia.org/wiki/Shapley_value">https://en.wikipedia.org/wiki/Shapley_value</a></li>
</ol>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/xai/" rel="tag">XAI</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/shap/" rel="tag">SHAP</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/shapley-sampling-value/" rel="tag">Shapley Sampling Value</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<figure class="authorbox__avatar">
		<img alt="STATKWON avatar" src="/img/avatar.png" class="avatar" height="90" width="90">
	</figure>
	<div class="authorbox__header">
		<span class="authorbox__name">About STATKWON</span>
	</div>
	<div class="authorbox__description">
		Data Scientist? Developer?
	</div>
</div>

<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/paper_review/analysis_of_regression_in_game_theory_approach/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Analysis of Regression in Game Theory Approach</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/paper_review/a_unified_approach_to_interpreting_model_predictions/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">A Unified Approach to Interpreting Model Predictions</p>
		</a>
	</div>
</nav>

<section class="comments">
	<div id="disqus_thread"></div>
<script type="application/javascript">
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "statkwon" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 STATKWON.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
<script src="/js/custom.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async>
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\[','\]']],
            processEscapes: true,
            processEnvironments: true,
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            TeX: { equationNumbers: { autoNumber: "AMS" },
            extensions: ["AMSmath.js", "AMSsymbols.js"] }
        }
    });
    MathJax.Hub.Queue(function() {
        
        
        
        var all = MathJax.Hub.getAllJax(), i;
        for(i = 0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
</body>
</html>
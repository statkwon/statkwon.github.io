<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Coordinate Descent - ML LAB</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Coordinate Descent" />
<meta property="og:description" content="Coordinate Descent convex &amp; differentiable한 함수 $g$와 convex한 함수 $h$에 대하여 $f(\mathbf{x})=g(\mathbf{x})&#43;\sum_{i=1}^nh_i(x_i)$ 일 때, 각 좌표축에 대하여 $f$를 최소화시킨 점 $\mathbf{x}$는 항상 global minimizer이다. (증명은 첫 번째 reference 참고) 따라서 다음과 같은 과정을 반복하여 $f$의 global minimizer를 근사할 수 있다.
For $k=1, 2, 3, \ldots$
$x_1^{(k)}\in\underset{x_1}{\text{argmin}}f(x_1, x_2^{(k-1)}, x_3^{(k-1)}, \ldots, x_n^{(k-1)})$ $x_2^{(k)}\in\underset{x_2}{\text{argmin}}f(x_1^{(k)}, x_2, x_3^{(k-1)}, \ldots, x_n^{(k-1)})$ $x_3^{(k)}\in\underset{x_3}{\text{argmin}}f(x_1^{(k)}, x_2^{(k)}, x_3, \ldots, x_n^{(k-1)})$ $\cdots$ $x_n^{(k)}\in\underset{x_n}{\text{argmin}}f(x_1^{(k)}, x_2^{(k)}, x_3^{(k)}, \ldots, x_n)$
초깃값 $\mathbf{x}^{(0)}$로는 적당한 값을 사용한다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://statkwon.github.io/ml/coordinate_descent/" /><meta property="article:section" content="ml" />
<meta property="article:published_time" content="2023-12-21T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-12-22T00:00:00+00:00" />

		<meta itemprop="name" content="Coordinate Descent">
<meta itemprop="description" content="Coordinate Descent convex &amp; differentiable한 함수 $g$와 convex한 함수 $h$에 대하여 $f(\mathbf{x})=g(\mathbf{x})&#43;\sum_{i=1}^nh_i(x_i)$ 일 때, 각 좌표축에 대하여 $f$를 최소화시킨 점 $\mathbf{x}$는 항상 global minimizer이다. (증명은 첫 번째 reference 참고) 따라서 다음과 같은 과정을 반복하여 $f$의 global minimizer를 근사할 수 있다.
For $k=1, 2, 3, \ldots$
$x_1^{(k)}\in\underset{x_1}{\text{argmin}}f(x_1, x_2^{(k-1)}, x_3^{(k-1)}, \ldots, x_n^{(k-1)})$ $x_2^{(k)}\in\underset{x_2}{\text{argmin}}f(x_1^{(k)}, x_2, x_3^{(k-1)}, \ldots, x_n^{(k-1)})$ $x_3^{(k)}\in\underset{x_3}{\text{argmin}}f(x_1^{(k)}, x_2^{(k)}, x_3, \ldots, x_n^{(k-1)})$ $\cdots$ $x_n^{(k)}\in\underset{x_n}{\text{argmin}}f(x_1^{(k)}, x_2^{(k)}, x_3^{(k)}, \ldots, x_n)$
초깃값 $\mathbf{x}^{(0)}$로는 적당한 값을 사용한다."><meta itemprop="datePublished" content="2023-12-21T00:00:00+00:00" />
<meta itemprop="dateModified" content="2023-12-22T00:00:00+00:00" />
<meta itemprop="wordCount" content="199">
<meta itemprop="keywords" content="Optimization," />
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GE14Z4QTKV"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-GE14Z4QTKV', { 'anonymize_ip': false });
}
</script>

</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="INTUITIVE STATISTICAL LEARNING" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">INTUITIVE STATISTICAL LEARNING</div>
					<div class="logo__tagline">Wanna be a Skillful ML Engineer</div>
				</div>
		</a>
	</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/about/">
				
				<span class="menu__text">About</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Coordinate Descent</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2023-12-21T00:00:00Z">2023-12-21</time>
	<time class="meta__text" datetime="2023-12-22T00:00:00Z">(Last Modified: 2023-12-22)</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/ml/" rel="category">ML</a>
	</span>
</div></div>
		</header>
		
<div class="post__toc toc">
	<div class="toc__title">Page content</div>
	<div class="toc__menu">
		<nav id="TableOfContents">
  <ul>
    <li><a href="#coordinate-descent">Coordinate Descent</a></li>
    <li><a href="#python-code-for-example">Python Code for Example</a></li>
  </ul>
</nav>
	</div>
</div><div class="content post__content clearfix">
			<h2 id="coordinate-descent">Coordinate Descent</h2>
<p>convex &amp; differentiable한 함수 $g$와 convex한 함수 $h$에 대하여 $f(\mathbf{x})=g(\mathbf{x})+\sum_{i=1}^nh_i(x_i)$ 일 때, 각 좌표축에 대하여 $f$를 최소화시킨 점 $\mathbf{x}$는 항상 global minimizer이다. (증명은 첫 번째 reference 참고) 따라서 다음과 같은 과정을 반복하여 $f$의 global minimizer를 근사할 수 있다.</p>
<blockquote>
<p>For $k=1, 2, 3, \ldots$</p>
<p>$x_1^{(k)}\in\underset{x_1}{\text{argmin}}f(x_1, x_2^{(k-1)}, x_3^{(k-1)}, \ldots, x_n^{(k-1)})$ <br>
$x_2^{(k)}\in\underset{x_2}{\text{argmin}}f(x_1^{(k)}, x_2, x_3^{(k-1)}, \ldots, x_n^{(k-1)})$ <br>
$x_3^{(k)}\in\underset{x_3}{\text{argmin}}f(x_1^{(k)}, x_2^{(k)}, x_3, \ldots, x_n^{(k-1)})$ <br>
$\cdots$ <br>
$x_n^{(k)}\in\underset{x_n}{\text{argmin}}f(x_1^{(k)}, x_2^{(k)}, x_3^{(k)}, \ldots, x_n)$</p>
</blockquote>
<p>초깃값 $\mathbf{x}^{(0)}$로는 적당한 값을 사용한다.</p>
<h2 id="python-code-for-example">Python Code for Example</h2>
<p>Coordinate Descent 방식을 사용하여 Linear regression의 회귀 계수를 구해보자. 우리의 목표는 $f(\boldsymbol{\beta})=(\mathbf{y}-X\boldsymbol{\beta})^T(\mathbf{y}-X\boldsymbol{\beta})$를 최소화하는 $\boldsymbol{\beta}$를 찾는 것이므로,</p>
<p>$$\begin{align}
\nabla_if(\boldsymbol{\beta})&amp;=\mathbf{x}_i^T(\mathbf{y}-X\boldsymbol{\beta}) \\
&amp;=\mathbf{x}_i^T(\mathbf{y}-\mathbf{x}_i\beta_i-X_{-i}\boldsymbol{\beta}_{-i}) \\
&amp;=0
\end{align}$$</p>
<p>을 만족하는 $\beta_i=\dfrac{\mathbf{x}_i^T(\mathbf{y}-X_{-i}\boldsymbol{\beta}_{-i})}{X_i^TX_i}$로 업데이트를 진행하면 된다. 초깃값으로는 $\boldsymbol{\beta}^{(0)}=\mathbf{0}$을 사용하였다.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> make_regression
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">coordinate_descent</span>(X: np<span style="color:#f92672">.</span>ndarray, y: np<span style="color:#f92672">.</span>ndarray, n_iter: int):
</span></span><span style="display:flex;"><span>    _, p <span style="color:#f92672">=</span> X<span style="color:#f92672">.</span>shape
</span></span><span style="display:flex;"><span>    beta <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros(p)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(n_iter):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(p):
</span></span><span style="display:flex;"><span>            X_i <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>column_stack((X[:, :i], X[:, (i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>):]))
</span></span><span style="display:flex;"><span>            beta_i <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>concatenate((beta[:i], beta[(i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>):]))
</span></span><span style="display:flex;"><span>            beta[i] <span style="color:#f92672">=</span> (X[:, i]<span style="color:#f92672">.</span>T <span style="color:#f92672">@</span> (y <span style="color:#f92672">-</span> X_i <span style="color:#f92672">@</span> beta_i)) <span style="color:#f92672">/</span> (X[:, i]<span style="color:#f92672">.</span>T <span style="color:#f92672">@</span> X[:, i])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> beta
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>X, y, coef <span style="color:#f92672">=</span> make_regression(n_samples<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, n_features<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, noise<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, coef<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>print(coef)  <span style="color:#75715e"># [45.70587613 85.71249175 97.99623263 11.73155642 42.37063535]</span>
</span></span><span style="display:flex;"><span>beta <span style="color:#f92672">=</span> coordinate_descent(X, y, <span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>print(beta)  <span style="color:#75715e"># [45.69972366 85.72175552 98.00526381 11.72151389 42.37038922]</span>
</span></span></code></pre></div><hr>
<p><strong>Reference</strong></p>
<ol>
<li><a href="https://convex-optimization-for-all.github.io/contents/chapter23/2021/03/28/23_01_Coordinate_descent/">https://convex-optimization-for-all.github.io/contents/chapter23/2021/03/28/23_01_Coordinate_descent/</a></li>
</ol>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/optimization/" rel="tag">Optimization</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<figure class="authorbox__avatar">
		<img alt="STATKWON avatar" src="/img/avatar.png" class="avatar" height="90" width="90">
	</figure>
	<div class="authorbox__header">
		<span class="authorbox__name">About STATKWON</span>
	</div>
	<div class="authorbox__description">
		Wanna be a Skillful ML Engineer
	</div>
</div>

<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/ml/subgradient/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Subgradient</p>
		</a>
	</div>
</nav>

<section class="comments">
	<div id="disqus_thread"></div>
<script type="application/javascript">
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "statkwon" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 STATKWON.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async>
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\[','\]']],
            processEscapes: true,
            processEnvironments: true,
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            TeX: { equationNumbers: { autoNumber: "AMS" },
            extensions: ["AMSmath.js", "AMSsymbols.js"] }
        }
    });
    MathJax.Hub.Queue(function() {
        
        
        
        var all = MathJax.Hub.getAllJax(), i;
        for(i = 0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

</body>
</html>